{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DCGAN_solutions.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"vVyZZyp5wOw_","colab_type":"text"},"source":["## Deep Convolutional GAN\n","\n","This exercise is based on the [PyTorch tutorial](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html) on DCGAN.\n"]},{"cell_type":"code","metadata":{"id":"raAy05AXvQoe","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","import time\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zpom-KItlrkL","colab_type":"text"},"source":["## For this exercise it is recommended to use the GPU!"]},{"cell_type":"code","metadata":{"id":"HECwoyeXvZb9","colab_type":"code","outputId":"a813c57a-cc1e-4884-e4c2-c76b3e78bc6d","executionInfo":{"status":"ok","timestamp":1576593546701,"user_tz":-60,"elapsed":1439,"user":{"displayName":"Ron van Bree","photoUrl":"","userId":"10574495138637938052"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["\n","use_cuda = True\n","\n","if use_cuda and torch.cuda.is_available():\n","  device = torch.device('cuda')\n","else:\n","  device = torch.device('cpu')\n","\n","device"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"MK8Emkm-lyUg","colab_type":"text"},"source":["### Load the CIFAR10 dataset\n","\n","Feel free to try other datasets as well, such as the Celeb-A Faces Dataset which is used in the [tutorial](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html) on which this exercise is based."]},{"cell_type":"code","metadata":{"id":"D_pAwOzsvZhD","colab_type":"code","outputId":"eae609cd-e40d-4caa-e2cb-468523a48dce","executionInfo":{"status":"ok","timestamp":1576593562734,"user_tz":-60,"elapsed":14153,"user":{"displayName":"Ron van Bree","photoUrl":"","userId":"10574495138637938052"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["import torchvision\n","import torchvision.transforms as transforms\n","\n","transform_train = transforms.Compose([\n","    transforms.Scale(64),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data_cifar', train=True,\n","                                        download=True, transform=transform_train)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data_cifar', train=False,\n","                                       download=True, transform=transform_test)\n","\n","batch_size = 128\n","\n","c, w, h = 3, 32, 32\n","\n","trainloader = torch.utils.data.DataLoader(trainset,\n","                                          batch_size=batch_size,\n","                                          shuffle=True)\n","\n","testloader = torch.utils.data.DataLoader(testset,\n","                                         batch_size=batch_size,\n","                                         shuffle=True)\n","\n","classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:220: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n","  \"please use transforms.Resize instead.\")\n","\r0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data_cifar/cifar-10-python.tar.gz\n"],"name":"stdout"},{"output_type":"stream","text":["170500096it [00:09, 18174836.01it/s]                               \n"],"name":"stderr"},{"output_type":"stream","text":["Extracting ./data_cifar/cifar-10-python.tar.gz to ./data_cifar\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wkk4g_-hoEoI","colab_type":"text"},"source":["### Define the Generator and Discriminator models"]},{"cell_type":"code","metadata":{"id":"SbqyYkSZvZkf","colab_type":"code","colab":{}},"source":["\n","n_noise = 100  # Size of the noise vector\n","n_g_channels = 64\n","n_d_channels = 64\n","\n","class Generator(nn.Module):\n","    def __init__(self):\n","        super(Generator, self).__init__()\n","\n","        self.model = nn.Sequential(\n","            # input is Z, going into a convolution\n","            nn.ConvTranspose2d(n_noise, n_g_channels * 8, kernel_size=(4, 4), stride=1, padding=0, bias=False),\n","            nn.BatchNorm2d(n_g_channels * 8),\n","            nn.ReLU(),\n","            # state size. (n_g_channels*8) x 4 x 4\n","            nn.ConvTranspose2d(n_g_channels * 8, n_g_channels * 4, kernel_size=(4, 4), stride=2, padding=1, bias=False),\n","            nn.BatchNorm2d(n_g_channels * 4),\n","            nn.ReLU(),\n","            # state size. (n_g_channels*4) x 8 x 8\n","            nn.ConvTranspose2d(n_g_channels * 4, n_g_channels * 2, kernel_size=(4, 4), stride=2, padding=1, bias=False),\n","            nn.BatchNorm2d(n_g_channels * 2),\n","            nn.ReLU(),\n","            # state size. (n_g_channels*2) x 16 x 16\n","            nn.ConvTranspose2d(n_g_channels * 2,     n_g_channels, kernel_size=(4, 4), stride=2, padding=1, bias=False),\n","            nn.BatchNorm2d(n_g_channels),\n","            nn.ReLU(),\n","            # state size. (n_g_channels) x 32 x 32\n","            nn.ConvTranspose2d(    n_g_channels,      c, kernel_size=(4, 4), stride=2, padding=1, bias=False),\n","            nn.Tanh()\n","            # state size. c x 64 x 64\n","        )\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","\n","class Discriminator(nn.Module):\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","        self.model = nn.Sequential(\n","            # input is c x 64 x 64\n","            nn.Conv2d(c, n_d_channels, kernel_size=(4, 4), stride=2, padding=1, bias=False),\n","            # nn.LeakyReLU(0.2, inplace=True),\n","            nn.LeakyReLU(0.2),\n","            # state size. (n_d_channels) x 32 x 32\n","            nn.Conv2d(n_d_channels, n_d_channels * 2, kernel_size=(4, 4), stride=2, padding=1, bias=False),\n","            nn.BatchNorm2d(n_d_channels * 2),\n","            # nn.LeakyReLU(0.2, inplace=True),\n","            nn.LeakyReLU(0.2),\n","            # state size. (n_d_channels*2) x 16 x 16\n","            nn.Conv2d(n_d_channels * 2, n_d_channels * 4, kernel_size=(4, 4), stride=2, padding=1, bias=False),\n","            nn.BatchNorm2d(n_d_channels * 4),\n","            # nn.LeakyReLU(0.2, inplace=True),\n","            nn.LeakyReLU(0.2),\n","            # state size. (n_d_channels*4) x 8 x 8\n","            nn.Conv2d(n_d_channels * 4, n_d_channels * 8, kernel_size=(4, 4), stride=2, padding=1, bias=False),\n","            nn.BatchNorm2d(n_d_channels * 8),\n","            # nn.LeakyReLU(0.2, inplace=True),\n","            nn.LeakyReLU(0.2),\n","            # state size. (n_d_channels*8) x 4 x 4\n","            nn.Conv2d(n_d_channels * 8, 1, kernel_size=(4, 4), stride=1, padding=0, bias=False),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        output = self.model(x)\n","        return output.view(-1, 1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ep4fjKVYvZeb","colab_type":"code","outputId":"37abff75-6c8e-45c8-c223-e165cf113f88","executionInfo":{"status":"ok","timestamp":1576593780186,"user_tz":-60,"elapsed":517,"user":{"displayName":"Ron van Bree","photoUrl":"","userId":"10574495138637938052"}},"colab":{"base_uri":"https://localhost:8080/","height":612}},"source":["\n","G = Generator().to(device)\n","print(G)\n","\n","D = Discriminator().to(device)\n","print(D)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Generator(\n","  (model): Sequential(\n","    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n","    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU()\n","    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (8): ReLU()\n","    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (11): ReLU()\n","    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (13): Tanh()\n","  )\n",")\n","Discriminator(\n","  (model): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (1): LeakyReLU(negative_slope=0.2)\n","    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (4): LeakyReLU(negative_slope=0.2)\n","    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (7): LeakyReLU(negative_slope=0.2)\n","    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (10): LeakyReLU(negative_slope=0.2)\n","    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n","    (12): Sigmoid()\n","  )\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O7jf8QIXxpIi","colab_type":"code","colab":{}},"source":["\n","criterion = nn.BCELoss()\n","\n","# setup optimizers\n","D_optimizer = optim.Adam(D.parameters(), lr=0.0001)\n","G_optimizer = optim.Adam(G.parameters(), lr=0.0001)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-czNs8qam2_7","colab_type":"text"},"source":["### Define a function that displays an image tensor"]},{"cell_type":"code","metadata":{"id":"_flek_8cQuGo","colab_type":"code","colab":{}},"source":["inverse_transform = transforms.Compose([transforms.Normalize(mean = [ 0., 0., 0. ], std = [ 1/0.229, 1/0.224, 1/0.225 ]), \n","                                        transforms.Normalize(mean = [ -0.485, -0.456, -0.406 ], std = [ 1., 1., 1. ]),\n","                               ])\n","\n","# Function to show an image tensor\n","def show(X):\n","    X = X.cpu()\n","    X = inverse_transform(X)\n","\n","    plt.imshow(np.transpose(X.numpy(), (1, 2, 0)))\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mP0ygGx8m79R","colab_type":"text"},"source":["### Train the Generator and Discriminator models"]},{"cell_type":"code","metadata":{"id":"LwLiRs82xpLY","colab_type":"code","outputId":"2bdae540-5009-4338-e7f5-ab7f9b267e9a","executionInfo":{"status":"ok","timestamp":1576601693910,"user_tz":-60,"elapsed":98268,"user":{"displayName":"Ron van Bree","photoUrl":"","userId":"10574495138637938052"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1Q9DR1I-OigidcaWWOQj6HiYD94mXTiTP"}},"source":["start=time.time()\n","\n","n_show = 16  # Number of generated images that are shown during training\n","\n","fixed_noise = torch.FloatTensor(batch_size, n_noise, 1, 1).normal_(0, 1).to(device)\n","\n","for epoch in range(0,200):\n","\n","  G.train()  # Put the networks in train mode\n","  D.train()\n","  for i, (x_batch, y_batch) in enumerate(trainloader):\n","    x_batch, y_batch = x_batch.to(device), y_batch.to(device)  # Move the data to the device that is used\n","\n","    ############################\n","    # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n","    ###########################\n","    D_optimizer.zero_grad()\n","\n","    # Train on real data\n","    ones_batch = torch.ones(x_batch.size(0)).to(device)  # Get a batch of ones indicating these are real images\n","    output_real = D(x_batch)  # Discriminate the images\n","    D_real_loss = criterion(output_real, ones_batch)\n","\n","    # Train on fake data\n","    noise = torch.normal(mean=0, std=1, size=(batch_size, n_noise, 1, 1)).to(device)  # Create random noise as input for G\n","    x_batch_fake = G(noise)  # Create fake images using the generator network\n","    output_fake = D(x_batch_fake.detach())  # Discriminate the images. Detach the tensor for the computation graph so G's parameters won't be optimized here\n","    zero_batch = torch.zeros(x_batch_fake.size(0)).to(device)  # Get a batch of zeros indicating these are fake images\n","    D_fake_loss = criterion(output_fake, zero_batch)\n","    \n","    D_loss = D_real_loss + D_fake_loss\n","    D_loss.backward()\n","    D_optimizer.step()\n","\n","    ############################\n","    # (2) Update G network: maximize log(D(G(z)))\n","    ###########################\n","    G_optimizer.zero_grad()\n","\n","    ones_batch = torch.ones(x_batch_fake.size(0)).to(device)  # Get a batch of ones indicating these are real images\n","    output_fake = D(x_batch_fake)\n","    G_loss = criterion(output_fake, ones_batch)\n","    G_loss.backward()\n","    G_optimizer.step()\n","\n","    elapsed = time.time() - start  # Keep track of how much time has elapsed\n","\n","    if not i % 20:\n","      print(f'epoch: {epoch}, time: {elapsed:.3f}s, D loss: {D_loss.item():.3f}, G loss: {G_loss.item():.3f}')\n","    if not i % 100:\n","      show(torchvision.utils.make_grid(x_batch_fake[:n_show].detach()))\n","\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"kYxj6EFExpR9","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yg8NYNH_xpFO","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aVynFOlcvZXl","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}