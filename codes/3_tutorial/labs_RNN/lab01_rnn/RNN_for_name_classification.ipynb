{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9C20DXlMOAi9",
    "colab_type": "text"
   },
   "source": [
    "# Classifying names with a character-level RNN\n",
    "In this notebook we will use a recurrent neural network to predict the language from which certain surnames originate. When given some surname the network outputs a probability distribution over 18 possible languages corresponding to the likelyhood that they originate from these languages. \n",
    "\n",
    "This exercise was taken from the [PyTorch website](https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4t1dQLLZDKc",
    "colab_type": "text"
   },
   "source": [
    "### Download the dataset\n",
    "The dataset that is used can be downloaded [here](https://download.pytorch.org/tutorial/data.zip). Extract it to the directory where this notebook is located.\n",
    "Included in the ``data/names`` directory are 18 text files named as\n",
    "\"[Language].txt\". Each file contains a bunch of names, one name per\n",
    "line, mostly romanized (but we still need to convert from Unicode to\n",
    "ASCII)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNu_cHzjcUk8",
    "colab_type": "text"
   },
   "source": [
    "If you are running this notebook on Colab you can access the dataset by storing it on your Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "eo3dBmNZcQZr",
    "colab_type": "code",
    "outputId": "48ff91d2-0f98-4d5c-cb5b-42351ca45c61",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.575820225896E12,
     "user_tz": -60.0,
     "elapsed": 2825.0,
     "user": {
      "displayName": "Ron van Bree",
      "photoUrl": "",
      "userId": "10574495138637938052"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pPJHoYlkdot3",
    "colab_type": "text"
   },
   "source": [
    "**Change the following path variable such that it points to the location of the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "GdI9hWoEd6xi",
    "colab_type": "code",
    "outputId": "2e8b7bc3-8211-4eec-ab71-5344ec20c748",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.575820229986E12,
     "user_tz": -60.0,
     "elapsed": 963.0,
     "user": {
      "displayName": "Ron van Bree",
      "photoUrl": "",
      "userId": "10574495138637938052"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arabic.txt',\n",
       " 'Irish.txt',\n",
       " 'Chinese.txt',\n",
       " 'Italian.txt',\n",
       " 'Dutch.txt',\n",
       " 'English.txt',\n",
       " 'Czech.txt',\n",
       " 'Greek.txt',\n",
       " 'German.txt',\n",
       " 'French.txt',\n",
       " 'Japanese.txt',\n",
       " 'Russian.txt',\n",
       " 'Polish.txt',\n",
       " 'Spanish.txt',\n",
       " 'Scottish.txt',\n",
       " 'Portuguese.txt',\n",
       " 'Vietnamese.txt',\n",
       " 'Korean.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path_to_data = './gdrive/My Drive/DL_1920/codes/3_tutorial/labs_RNN/lab01_rnn/'  # TODO -- set this to the right location!\n",
    "\n",
    "os.listdir(path_to_data + '/data/names/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTyw5SkeXVxu",
    "colab_type": "text"
   },
   "source": [
    "### Preparing the data\n",
    "We first preprocess the dataset by limiting ourselves to ASCII characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "6Ztn7HClez8U",
    "colab_type": "code",
    "outputId": "9e14ea05-37da-4765-f6c0-029cb5f7bf4d",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.575820233114E12,
     "user_tz": -60.0,
     "elapsed": 651.0,
     "user": {
      "displayName": "Ron van Bree",
      "photoUrl": "",
      "userId": "10574495138637938052"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slusarski\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "print(unicodeToAscii('Ślusàrski'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "8daKzr0eg7LT",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# Build a dictionary containing a list of names for each language\n",
    "names_per_language = dict()\n",
    "languages = list()  # Keep a list containing all languages\n",
    "\n",
    "def readNames(file_path):  # Define a function that reads all names from some file in /data/names/ and converts them to ASCII\n",
    "  with open(file_path, encoding='utf-8') as f:\n",
    "    unicode_names = f.read().strip().split('\\n')  # Split the file on new lines. Each line contains a name (in unicode)\n",
    "    return [unicodeToAscii(name) for name in unicode_names]  # Convert all names to ASCII\n",
    "\n",
    "# For all files in /data/names/ read the names. Group the names by the language they are in\n",
    "\n",
    "for filename in os.listdir(path_to_data + 'data/names/'):\n",
    "  language, _ = filename.split('.')  # Remove the file extention to obtain the class label (the language)\n",
    "  languages.append(language)\n",
    "  names = readNames(path_to_data + 'data/names/' + filename)  # Read the names in the current file\n",
    "  names_per_language[language] = names\n",
    "\n",
    "n_languages = len(languages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vYL9BPerj2BB",
    "colab_type": "text"
   },
   "source": [
    "Now we have ``names_per_language``, a dictionary mapping each language to a list of names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "QHOPEma4j2Jj",
    "colab_type": "code",
    "outputId": "b316449e-f1b7-4ad9-afa2-2e898a12b6d5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.575820241407E12,
     "user_tz": -60.0,
     "elapsed": 625.0,
     "user": {
      "displayName": "Ron van Bree",
      "photoUrl": "",
      "userId": "10574495138637938052"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abandonato', 'Abatangelo', 'Abatantuono', 'Abate', 'Abategiovanni']\n"
     ]
    }
   ],
   "source": [
    "print(names_per_language['Italian'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrO3p0ciXdDh",
    "colab_type": "text"
   },
   "source": [
    "### Exercise - Transforming names into suitable inputs\n",
    "\n",
    "Now that we have all the names organized, we need to turn them into\n",
    "Tensors to make any use of them.\n",
    "\n",
    "To represent a single letter, we use a \"one-hot vector\" of size\n",
    "``<1 x n_letters>``. A one-hot vector is filled with 0s except for a 1\n",
    "at index of the current letter, e.g. ``\"b\" = <0 1 0 0 0 ...>``.\n",
    "\n",
    "To make a word we join a bunch of those into a 2D matrix\n",
    "``<line_length x 1 x n_letters>``.\n",
    "\n",
    "That extra 1 dimension is because PyTorch assumes everything is in\n",
    "batches - we're just using a batch size of 1 here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Z8e9Kdxpl6sS",
    "colab_type": "code",
    "outputId": "dc9af26c-20c0-4659-97a2-7d178f515d81",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.575820245027E12,
     "user_tz": -60.0,
     "elapsed": 909.0,
     "user": {
      "displayName": "Ron van Bree",
      "photoUrl": "",
      "userId": "10574495138637938052"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0.]])\n",
      "torch.Size([5, 1, 57])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Find letter index from all_letters, e.g. \"a\" = 0\n",
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
    "def letterToTensor(letter):\n",
    "    pass  # COMPLETE THIS CODE\n",
    "\n",
    "# Turn a line into a <line_length x 1 x n_letters>,\n",
    "# or an array of one-hot letter vectors\n",
    "def lineToTensor(line):\n",
    "    pass  # COMPLETE THIS CODE\n",
    "\n",
    "print(letterToTensor('J'))\n",
    "\n",
    "print(lineToTensor('Jones').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3PZ8LZlXiur",
    "colab_type": "text"
   },
   "source": [
    "### Exercise - Define a RNN architecture\n",
    "\n",
    "Create a neural network that takes as input some encoding of a character as well as a hidden state tensor. These two tensors are concatenated and passed to the following:\n",
    "* a linear layer that produces the next hidden state tensor (no activation function)\n",
    "* a linear layer that produces an output tensor (no activation function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "02jJFESsnA3W",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.i2h = ... # COMPLETE THIS CODE\n",
    "        self.i2o = ... # COMPLETE THIS CODE\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "\n",
    "        # COMPLETE THIS CODE\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "n_hidden = 128\n",
    "rnn = RNN(n_letters, n_hidden, n_languages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWuIJQnJ9NRn",
    "colab_type": "text"
   },
   "source": [
    "To run a step of this network we need to pass an input (in our case, the\n",
    "Tensor for the current letter) and a previous hidden state (which we\n",
    "initialize as zeros at first). We'll get back the output and a next hidden state (which we keep for the next\n",
    "step).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "jts3zvXo7mSD",
    "colab_type": "code",
    "outputId": "ded21516-e4da-4c6a-e6a1-5c63ff1c9c06",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.575820272527E12,
     "user_tz": -60.0,
     "elapsed": 1222.0,
     "user": {
      "displayName": "Ron van Bree",
      "photoUrl": "",
      "userId": "10574495138637938052"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 57])\n",
      "torch.Size([1, 57])\n",
      "torch.Size([1, 128])\n",
      "tensor([[0.0569, 0.0577, 0.0514, 0.0543, 0.0606, 0.0548, 0.0510, 0.0544, 0.0616,\n",
      "         0.0599, 0.0533, 0.0541, 0.0537, 0.0493, 0.0603, 0.0580, 0.0516, 0.0571]],\n",
      "       grad_fn=<ExpBackward>)\n"
     ]
    }
   ],
   "source": [
    "input_tensor = lineToTensor('Albert')\n",
    "hidden = torch.zeros(1, n_hidden)  # Initialize the hidden state as zeros\n",
    "\n",
    "print(input_tensor.shape)  # The name contains 6 characters which are all encoded as 1-hot vectors of length 57 (corresponding to all possible input characters)\n",
    "print(input_tensor[0].shape)  # Show the shape of a single character. The 1 is the batch dimension. In this example we set the batch size to 1 for simplicity\n",
    "print(hidden.shape)  # Show the shape of the hidden state vector\n",
    "\n",
    "output, next_hidden = rnn(input_tensor[0], hidden)  # Pass the first letter in the name to the network, as well as the initial hidden state\n",
    "\n",
    "print(F.softmax(output, dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mhR9-5IKXoj2",
    "colab_type": "text"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pDvQVMhANx2",
    "colab_type": "text"
   },
   "source": [
    "First we will define a function to sample random data points from the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "cMF_KUeH_nNt",
    "colab_type": "code",
    "outputId": "fc45fd72-81d3-4b9d-9f0a-f87df527266b",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.575820277354E12,
     "user_tz": -60.0,
     "elapsed": 744.0,
     "user": {
      "displayName": "Ron van Bree",
      "photoUrl": "",
      "userId": "10574495138637938052"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0, Name: Scott, Language: Scottish\n",
      "Example 1, Name: Nomikos, Language: Greek\n",
      "Example 2, Name: Zhi, Language: Chinese\n",
      "Example 3, Name: Kieu, Language: Vietnamese\n",
      "Example 4, Name: Aberquero, Language: Spanish\n",
      "Example 5, Name: Marquering, Language: Dutch\n",
      "Example 6, Name: Kaplanek, Language: Czech\n",
      "Example 7, Name: Sakoda, Language: Japanese\n",
      "Example 8, Name: Satoh, Language: Japanese\n",
      "Example 9, Name: Alamilla, Language: Spanish\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def random_train_example():\n",
    "  # Select a random name in some random language\n",
    "  language = random.choice(languages)\n",
    "  name = random.choice(names_per_language[language])\n",
    "  # Convert the name to a suitable input tensor\n",
    "  name_tensor = lineToTensor(name)\n",
    "  # Convert the language to a suitable target tensor\n",
    "  lang_tensor = torch.LongTensor([languages.index(language)])  # The tensor datatype is 'long' as it contains an integer corresponding to the index of the language\n",
    "  return language, name, lang_tensor, name_tensor\n",
    "\n",
    "for i in range(10):\n",
    "    language, name, lang_tensor, name_tensor = random_train_example()\n",
    "\n",
    "    print(f'Example {i}, Name: {name}, Language: {language}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uzNuGzIVZOZE",
    "colab_type": "text"
   },
   "source": [
    "Next we define a function that performs stochastic gradient descent using a single data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "GNMfSkKMDF2V",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(rnn.parameters(), lr=0.005)\n",
    "\n",
    "def train_on_example(name_tensor, language_tensor):\n",
    "  hidden_state = torch.zeros(1, n_hidden)\n",
    "\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  for character_tensor in name_tensor:  # Perform a forward pass for each character in the name\n",
    "    out, hidden_state = ...  # COMPLETE THIS CODE\n",
    "\n",
    "  loss = criterion(out, language_tensor)\n",
    "  loss.backward()\n",
    "\n",
    "  optimizer.step()\n",
    "\n",
    "  return out, loss.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aEb04AhsZgYE",
    "colab_type": "text"
   },
   "source": [
    "Now iterate through the dataset to train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "EdcLFM-VFJMw",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "n_iters = 100000\n",
    "\n",
    "for i in range(1, n_iters + 1):\n",
    "  language, name, lang_tensor, name_tensor = random_train_example()\n",
    "  output, loss = train_on_example(name_tensor, lang_tensor)\n",
    "\n",
    "  if not i % 1000:\n",
    "    lang_pred = languages[torch.argmax(output).item()]\n",
    "\n",
    "    print(f'Example {i}, Loss: {loss:.3f} Name: {name:16s} Language: {language:16s} Classified as: {lang_pred:16s} {\"Correct\" if lang_pred == language else \"Incorrect\"}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VbACHnfkXuq9",
    "colab_type": "text"
   },
   "source": [
    "### Evaluating the network\n",
    "\n",
    "We now define a function that gives the network names you can enter manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "FDN60k38XVAw",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def predict(input_name, num_langs=3):\n",
    "  name_tensor = lineToTensor(input_name)\n",
    "  hidden_state = torch.zeros(1, n_hidden)\n",
    "  for character_tensor in name_tensor:\n",
    "    out, hidden_state = rnn(character_tensor, hidden_state) \n",
    "\n",
    "  dist = list(zip(languages, F.softmax(out, dim=1).squeeze()))\n",
    "\n",
    "  topk_langs = sorted(dist, key=lambda p: p[1].item())[-num_langs:]\n",
    "\n",
    "  for lang, p in reversed(topk_langs):\n",
    "    print(f'{lang}, {p.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "-qOBToI1N3XW",
    "colab_type": "code",
    "outputId": "5572c5b6-1dc2-4b5f-a802-434e4598a29e",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 580.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dovesky\n",
      "Czech, 0.45103010535240173\n",
      "Russian, 0.38874995708465576\n",
      "English, 0.06384486705064774\n",
      "Hazaki\n",
      "Japanese, 0.8367655277252197\n",
      "Polish, 0.1282850056886673\n",
      "Arabic, 0.010923446156084538\n",
      "Brune\n",
      "Scottish, 0.5156903862953186\n",
      "German, 0.15303932130336761\n",
      "English, 0.12645377218723297\n",
      "Jackson\n",
      "Scottish, 0.7522407174110413\n",
      "English, 0.1534046083688736\n",
      "Russian, 0.030946804210543633\n",
      "Satoshi\n",
      "Italian, 0.3838347792625427\n",
      "Japanese, 0.26992765069007874\n",
      "Arabic, 0.17385496199131012\n",
      "Lee\n",
      "Vietnamese, 0.5058001279830933\n",
      "Chinese, 0.3838532567024231\n",
      "French, 0.02899548038840294\n",
      "Hinton\n",
      "Scottish, 0.5770138502120972\n",
      "English, 0.14913064241409302\n",
      "Korean, 0.09496493637561798\n",
      "Schmidhuber\n",
      "German, 0.8255714774131775\n",
      "Arabic, 0.06226326897740364\n",
      "Dutch, 0.03400055691599846\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "  predict(input())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "RNN_for_name_classification.ipynb",
   "provenance": [
    {
     "file_id": "19Ubm0kUDdZAvzodCjkYSpYecN2p77KUQ",
     "timestamp": 1.575823623248E12
    }
   ],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
